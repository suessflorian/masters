\documentclass{article}
\begin{document}
(14th March, Week 3)
\section*{Cross-Validation (CV)}
Building ontop to hyper parameter discovery methods, we did a crude 70/30 split of training and testing data, and within the training data we split again via 70/30 ratio the training data set to surface what we call the validation set.

This splitting is interesting because it feels like we're suboptimally training a model on only 70\% of the data. Is there a method in which we can train on more then that, whilst still being able to self refer an accuracy measure? A long wind up to {\bf yes - indeed we can sir}.

\subsection*{Welcome to folding}
We parition our data set into a $k$-fold. Where each fold ("partition")

\end{document}
