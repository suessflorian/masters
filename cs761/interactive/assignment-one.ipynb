{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPSCI 761 22S2 Assignment 1\n",
    "\n",
    "- Lecturer: Anna Trofimova\n",
    "- School of Computer Science, The Univerity of Auckland\n",
    "- Last update 29th of July at 18:00pm, 2022\n",
    "$$\n",
    "% macros\n",
    "\\newcommand{\\indep}{\\perp \\!\\!\\!\\perp}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student:\n",
    "\n",
    "Florian Suess, fsue534"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission\n",
    "This interactive notebook contains the instructions to complete assignment 1; You should submit this notebook with the code and answers in one single file in .ipybn format with name assignment1.ipybn. **Write your name and UPI in the cell above** (to edit the markdown text double-click the cell).\n",
    "\n",
    "There is a maximum file size cap of 5MB, so make sure your submission does not exceed this size. The submitted notebook should contain all your source code and answers. You can add new cells and use markdown text to organise and explain your implementation/answer.\n",
    "\n",
    "Submit your files using CANVAS upload function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission deadline is **19th of August at 11.59pm, 2022.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plagiarism\n",
    "This is an individual assignment. Remember that **all** work submitted for this assignment must be your own **individual** work and no code\n",
    "sharing or copying is allowed. You may use code from the Internet only with suitable attribution\n",
    "of the source in your program. **Do not use public code repositories as your code might be copied.** Keep in mind that sharing parts of assignment solutions is a form of plagiarism. All submitted assignments will be run through plagiarism detection software to detect similarities to other submissions. You should carefully read the UoA policy on academic integrity and plagiarism. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "This assignment consists of two problems presented in a puzzle game context. For the first problem, you will be implementing a path search problem along with common search algorithms and evaluating their properties. For the second problem, you will be exploring how to define and solve a constraint satisfaction problem. To implement the solutions, you have to use AIPython code that provides you with many implemented classes and examples of their use.  \n",
    "\n",
    "When working with a Jupyter notebook, you can edit the \\*.py files either in the Jupyter interface (in your browser) or with your favorite editor (e.g., PyCharm). Whenever you save a \\*.py file, the notebook will reload their content directly.\n",
    "\n",
    "The libraries that you can use (and need) in this assignment are  the following (run the cell below to import the libraries):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"./aipython\")\n",
    "import time\n",
    "import numpy as np\n",
    "from aipython.searchGeneric import *\n",
    "from aipython.searchProblem import *\n",
    "from aipython.cspProblem import *\n",
    "from aipython.cspSearch import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tip: If you placed the notebook correctly it should not give you any errors.*\n",
    "\n",
    "*If you think that there are other libraries you might need then send an email to anna.trofimova@auckland.ac.nz to confirm.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Heuristics [5 marks]\n",
    "\n",
    "This part of the assignment is based on a popular puzzle, Game of Fifteen, also known as 15-puzzle. The game consists of 15 numbered tiles on a four by four grid where one tile is missing. To solve the puzzle, the tiles must be moved so that they are ordered from 1 to 15. The goal state of the puzzle is defined as a multidimensional array of digits#, where 0 represents the missing tile, as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = [[1, 2, 3, 4], \n",
    "        [5, 6, 7, 8], \n",
    "        [9, 10, 11, 12], \n",
    "        [13, 14, 15, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.1\n",
    "Edit the code below to implement a search problem class representing the Game of Fifteen that uses heuristic based on Manhattan Distance (h1). The class must be implemented by extending the class Search\\_problem. \n",
    "\n",
    "Manhattan Distance between two points $p1$ at $(x1, y1)$ and $p2$ at $(x2, y2)$ is $d_{M}(p1, p2) = |x1 - x2| + |y1 - y2|$\n",
    "\n",
    "*Tip: If you have problems understanding how to overwrite methods take a look at the implementation of Search_problem_from_explicit_graph class in searchProblem.py*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\"\"\"\n",
    "    PS: you have no idea how long it took me to realise that the nodes in this problem\n",
    "    is the entire board configuration, *not each individual tile*... neighbours of this node being all\n",
    "    board configurations that can be derived by 1 move (swapping the 0 tile with up/down/left/right if\n",
    "    permissible).\n",
    "\"\"\"\n",
    "\n",
    "class GameFifteenProblem(Search_problem):\n",
    "    ROWS=4\n",
    "    COLUMNS=4\n",
    "            \n",
    "    def __init__(self, start: list[list[int]], goal: list[list[int]]):\n",
    "        \"\"\"Sets problem, will throw ValueError if board and/or goal given isn't to spec\"\"\"\n",
    "        \n",
    "        def must_be_valid_board(board: list[list[int]]) -> None:\n",
    "            values: list[int] = []\n",
    "            if len(board) != self.ROWS:\n",
    "                raise ValueError(f\"the fifteen game boards provided must have exactly {self.ROWS} rows\")\n",
    "            for row in board:\n",
    "                if len(row) != self.COLUMNS:\n",
    "                    raise ValueError(f\"the fifteen game boards provided must have exactly {self.COLUMNS} columns\")\n",
    "                for value in row:\n",
    "                    values.append(value)\n",
    "            \n",
    "            values.sort()\n",
    "            if not np.array_equal(values, [i for i in range(16)]):\n",
    "                raise ValueError(f\"expect only 0,1,...,15 tiles as board input\")\n",
    "\n",
    "        must_be_valid_board(start)\n",
    "        must_be_valid_board(goal)\n",
    "        \n",
    "        self.start_tiles: list[list[int]] = start\n",
    "        self.goal_tiles: list[list[int]] = goal\n",
    "        return\n",
    "\n",
    " \n",
    "\n",
    "    def start_node(self):\n",
    "        \"\"\"Returns the start node, which in this case is the starting board configuration\"\"\"\n",
    "        return self.start_tiles\n",
    "    \n",
    "    def is_goal(self, board: list[list[int]]) -> bool:\n",
    "        \"\"\"Returns True if the given board (list of tiles) is the goal, otherwise False\"\"\"\n",
    "        for y, goal_row in enumerate(self.goal_tiles):\n",
    "            for x, value in enumerate(goal_row):\n",
    "                if board[y][x] != value:\n",
    "                    return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def neighbors(self, board: list[list[int]]) -> bool:\n",
    "        \"\"\"Returns a list of the arcs for the neighbors of board, note the neighbours are\n",
    "        at most four board configurations that are based on swaps with the 0 tile.\n",
    "        \n",
    "        for example: \n",
    "        return [Arc(node, to_neighbor_node1, cost1), Arc(node, to_neighbor_node2, cost2)]\"\"\"\n",
    "        \n",
    "        def swap(board: list[list[int]], zero: tuple[int, int], tile: tuple[int, int]):\n",
    "            \"\"\"Returns new board with zero and given tile swapped\"\"\"\n",
    "            swapped_board = copy.deepcopy(board)\n",
    "            \n",
    "            swapped_board[zero[1]][zero[0]] = board[tile[1]][tile[0]]\n",
    "            swapped_board[tile[1]][tile[0]] = 0\n",
    "                \n",
    "            return swapped_board\n",
    "        \n",
    "        neighbours: list[Arc] = []\n",
    "        for y, row in enumerate(board):\n",
    "            for x, value in enumerate(row):\n",
    "                if value == 0:\n",
    "                    \"\"\"can only ever swap the 0 tile with it's immediate neighbours\"\"\"\n",
    "                    zero_tile = (x, y)\n",
    "                    \n",
    "                    if y != 0:\n",
    "                        zero_tile_swapped_up = swap(board, zero_tile, (x, y-1))\n",
    "                        neighbours.append(Arc(board, zero_tile_swapped_up))\n",
    "                        \n",
    "                    if y + 1 != self.ROWS: \n",
    "                        zero_tile_swapped_down = swap(board, zero_tile, (x, y+1))\n",
    "                        neighbours.append(Arc(board, zero_tile_swapped_down))\n",
    "                        \n",
    "                    if x != 0: \n",
    "                        zero_tile_swapped_left = swap(board, zero_tile, (x-1, y))\n",
    "                        neighbours.append(Arc(board, zero_tile_swapped_left))\n",
    "                        \n",
    "                    if x + 1 != self.COLUMNS: \n",
    "                        zero_tile_swapped_right = swap(board, zero_tile, (x+1, y))\n",
    "                        neighbours.append(Arc(board, zero_tile_swapped_right))\n",
    "                    \n",
    "        return neighbours\n",
    "    \n",
    "    def heuristic(self, board: list[list[int]]) -> int:\n",
    "        \"\"\"Returns the heuristic value of the node \n",
    "        based on the Manhattan distance\"\"\"\n",
    "        \n",
    "        heuristic: int = 0\n",
    "            \n",
    "        def get_goal_position(target: int) -> tuple[int, int]:\n",
    "            for y, row in enumerate(self.goal_tiles):\n",
    "                for x, value in enumerate(row):\n",
    "                    if value == target:\n",
    "                        return (x, y)\n",
    "\n",
    "        for y, row in enumerate(board):\n",
    "            for x, value in enumerate(row):\n",
    "                goal_position = get_goal_position(value)\n",
    "                heuristic += ( abs(x-goal_position[0]) + abs(y-goal_position[1]) )\n",
    "                \n",
    "        return heuristic\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate the correctness of the problem class use the A* searcher algorithm (from searchGeneric.py) to find a solution. \n",
    "\n",
    "*Tip: The cost of the solution should be 9.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 paths have been expanded and 89 paths remain in the frontier\n",
      "Cost:  9\n"
     ]
    }
   ],
   "source": [
    "start = [[1, 2, 3, 4], \n",
    "         [9, 5, 6, 7], \n",
    "         [10, 11, 8, 0], \n",
    "         [13, 14, 15, 12]]\n",
    "\n",
    "puzzle = GameFifteenProblem(start, goal)\n",
    "searcher = AStarSearcher(puzzle)\n",
    "solution = searcher.search()\n",
    "print('Cost: ',  solution.cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.2 \n",
    "Implement search problem classes representing the Game of Fifteen that use heuristics based on Euclidean Distance (h2) and the number of the inversions of the permutation (h3). The classes must be implemented by extending the class GameFifteenProblem.\n",
    "\n",
    "Euclidean distance between two points $p1$ at $(x1, y1)$ and $p2$ at $(x2, y2)$ is $d_{E}(p1, p2) =  \\sqrt{(x1-x2)^{2}+ (y1-y2)^{2}}$\n",
    "\n",
    "An inversion of a permutation $(t_{1},t_{2},...,t_{n})$ of the elements in a finite n-element set of positive integers $A=\\{1,2,...,n\\}$ is the pair $(t_{j},t_{k})$, where $j<k$ and $t_{j}>t_{k}$.\n",
    "\n",
    "$\\sum_{j=1}^{N} \\sum_{k=j}^{N}    \\{t_{j} > t_{k}: 1, otherwise: 0\\}$, where $N$ is the total number of elements and $t_{i}$ is the value of i-th element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameFifteenProblemEuclidean(GameFifteenProblem):\n",
    "    def __init__(self, start: list[list[int]], goal: list[list[int]]):\n",
    "        (super().__init__(start, goal))\n",
    "\n",
    "    def heuristic(self, board: list[list[int]]):\n",
    "        heuristic: int = 0\n",
    "            \n",
    "        def get_goal_position(target: int) -> tuple[int, int]:\n",
    "            for y, row in enumerate(self.goal_tiles):\n",
    "                for x, value in enumerate(row):\n",
    "                    if value == target:\n",
    "                        return (x, y)\n",
    "\n",
    "        for y, row in enumerate(board):\n",
    "            for x, value in enumerate(row):\n",
    "                goal_position = get_goal_position(value)\n",
    "                \n",
    "                heuristic += ( (x-goal_position[0])**2 + (y-goal_position[1])**2 )**(1/2)\n",
    "                \n",
    "        return heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameFifteenProblemInversions(GameFifteenProblem):\n",
    "    def __init__(self, start, goal):\n",
    "        (super().__init__(start, goal))\n",
    "\n",
    "    def heuristic(self, board: list[list[int]]):\n",
    "\n",
    "        flattened_board: list[int] = []\n",
    "        for row in board:\n",
    "            for value in row:\n",
    "                flattened_board.append(value)\n",
    "        \n",
    "        heuristic: int = 0\n",
    "        for j in range(16):\n",
    "            for k in range(j, 16):\n",
    "                left, right = flattened_board[j], flattened_board[k]\n",
    "                \n",
    "                \"\"\" ignore zero tile completely \"\"\"\n",
    "                if left == 0 or right == 0:\n",
    "                    continue\n",
    "\n",
    "                if left > right:\n",
    "                    heuristic += 1\n",
    "\n",
    "        return heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.3\n",
    "Run A* Search algorithm with every heuristic for the following three start states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Position:  [[1, 2, 8, 3], [5, 6, 7, 4], [9, 15, 14, 11], [13, 10, 12, 0]]\n",
      "- Manhattan: 384 paths have been expanded and 682 paths remain in the frontier\n",
      "- Euclidean: 617 paths have been expanded and 1122 paths remain in the frontier\n",
      "- Inversions: 30 paths have been expanded and 62 paths remain in the frontier\n",
      "Starting Position:  [[1, 3, 6, 4], [5, 2, 8, 14], [9, 15, 7, 0], [13, 10, 12, 11]]\n",
      "- Manhattan: 533 paths have been expanded and 967 paths remain in the frontier\n",
      "- Euclidean: 431 paths have been expanded and 778 paths remain in the frontier\n",
      "- Inversions: 1029 paths have been expanded and 2422 paths remain in the frontier\n",
      "Starting Position:  [[1, 3, 6, 4], [5, 8, 15, 14], [9, 2, 7, 0], [13, 10, 12, 11]]\n",
      "- Manhattan: 14380 paths have been expanded and 25805 paths remain in the frontier\n",
      "- Euclidean: 24760 paths have been expanded and 46179 paths remain in the frontier\n",
      "- Inversions: 87774 paths have been expanded and 192844 paths remain in the frontier\n"
     ]
    }
   ],
   "source": [
    "# optimal path cost: 14\n",
    "start14 = [[1, 2, 8, 3],\n",
    "           [5, 6, 7, 4],\n",
    "           [9, 15, 14, 11],\n",
    "           [13, 10, 12, 0]]\n",
    "\n",
    "# optimal path cost: 17\n",
    "start17 = [[1, 3, 6, 4],\n",
    "           [5, 2, 8, 14],\n",
    "           [9, 15, 7, 0],\n",
    "           [13, 10, 12, 11]]\n",
    "\n",
    "# optimal path cost: 23\n",
    "start23 = [[1, 3, 6, 4],\n",
    "           [5, 8, 15, 14],\n",
    "           [9, 2, 7, 0],\n",
    "           [13, 10, 12, 11]]\n",
    "\n",
    "for start in [start14, start17, start23]:\n",
    "    print('Starting Position: ', start)\n",
    "    print('- Manhattan: ', end='')\n",
    "    manhattan_based_searcher = AStarSearcher(GameFifteenProblem(start, goal))\n",
    "    manhattan_based_searcher.search()\n",
    "    \n",
    "    print('- Euclidean: ', end='')\n",
    "    euclidean_based_searcher = AStarSearcher(GameFifteenProblemEuclidean(start, goal))\n",
    "    euclidean_based_searcher.search()\n",
    "    \n",
    "    print('- Inversions: ', end='')\n",
    "    inversions_based_searcher = AStarSearcher(GameFifteenProblemInversions(start, goal))\n",
    "    inversions_based_searcher.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each case record in the tables below the heuristic values for the start states, the number of the expanded nodes, and the costs of the solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Heuristic | h-value: start14 | h-value: start17 | h-value: start23 |\n",
    "|-----------|------------------|------------------|------------------|\n",
    "|Manhattan  | #                | #                | #                | \n",
    "|Euclidean  | #                | #                | #                | \n",
    "|Inversions | #                | #                | #                | \n",
    "\n",
    "| Heuristic | expanded: start14 | expanded: start17 | expanded: start23 |\n",
    "|-----------|-------------------|-------------------|-------------------|\n",
    "|Manhattan  | #                 | #                 | #                 | \n",
    "|Euclidean  | #                 | #                 | #                 |  \n",
    "|Inversions | #                 | #                 | #                 |  \n",
    "\n",
    "| Heuristic | path cost: start14 | path cost: start17 | path cost: start23 |\n",
    "|-----------|--------------------|--------------------|--------------------|\n",
    "|Manhattan  | #                  | #                  | #                  | \n",
    "|Euclidean  | #                  | #                  | #                  |\n",
    "|Inversions | #                  | #                  | #                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the performance of the A* search algorithm with each heuristic based on the results in the tables. Explain which heuristic is better/worse and why."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2:  Search algorithms [7 marks]\n",
    "\n",
    "*Tip: If you have problems understanding how to overwrite methods take a look at the implementation of AStarSearcher and  Searcher classes in searchGeneric.py*\n",
    "\n",
    "*Tip: To initialize the frontier think of the type of structure used by the algorithm to store generated nodes. If it uses a priority queue use FrontierPQ from serachGeneric.py*\n",
    "\n",
    "#### Task 2.1\n",
    "Implement a class that performs Breadth First Search by extending class Searcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All we change from the `Searcher` class is how we select from the frontier, so leaving all methods as is\n",
    "and swapping from a stack (`pop()`) to a queue (`pop(0)`).\n",
    "\n",
    "Otherwise straight from the `aipython/searchGeneric.py` implementation\n",
    "\"\"\"\n",
    "\n",
    "class BreadthFirstSearcher(Searcher):\n",
    "    def __init__(self,  problem) -> None:\n",
    "        super().__init__(problem)\n",
    "    \n",
    "    def initialize_frontier(self):\n",
    "        self.frontier = []\n",
    "    \n",
    "    def empty_frontier(self):\n",
    "        return self.frontier == []\n",
    "\n",
    "    def search(self):\n",
    "        while not self.empty_frontier():\n",
    "            path = self.frontier.pop(0)\n",
    "            self.display(2, \"Expanding:\",path,\"(cost:\",path.cost,\")\")\n",
    "            self.num_expanded += 1\n",
    "            if self.problem.is_goal(path.end()):\n",
    "                self.display(1, self.num_expanded, \"paths have been expanded and\", \n",
    "                             len(self.frontier), \"paths remain in the frontier\")\n",
    "                self.solution = path\n",
    "                return path\n",
    "            else:\n",
    "                neighs = self.problem.neighbors(path.end())\n",
    "                self.display(3,\"Neighbors are\", neighs)\n",
    "                for arc in reversed(list(neighs)):\n",
    "                    self.add_to_frontier(Path(path,arc))\n",
    "                self.display(3,\"Frontier:\",self.frontier)\n",
    "        self.display(1,\"No (more) solutions. Total of\",self.num_expanded,\"paths expanded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.2\n",
    "\n",
    "Implement a class that performs Iterative Deepening Search by extending class Searcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeDeepeningSearcher(Searcher):\n",
    "    def __init__(self, problem):\n",
    "        self.iterative_depth = 0\n",
    "        self.problem = problem\n",
    "        self.initialize_frontier()\n",
    "        self.num_expanded = 0\n",
    "        self.add_to_frontier(Path(problem.start_node()), 0)\n",
    "    \n",
    "    def initialize_frontier(self):\n",
    "        self.frontier = []\n",
    "\n",
    "    def empty_frontier(self):\n",
    "        return self.frontier == []\n",
    "\n",
    "    def add_to_frontier(self, path, depth):\n",
    "        self.frontier.append((path, depth))\n",
    "    \n",
    "    def search(self):\n",
    "        forced_deadends = 0 \n",
    "        \"\"\" \n",
    "            number of popped nodes in the frontier disregarded due to iterative depth, used\n",
    "            to decide wether to bump the iterative depth of the search, or wave hands re: no solution found\n",
    "        \"\"\"\n",
    "        \n",
    "        while not self.empty_frontier():\n",
    "            path, current_depth = self.frontier.pop()\n",
    "            self.display(2, \"Expanding:\",path,\"depth level: \", current_depth,\"(cost:\",path.cost,\")\")\n",
    "            self.num_expanded += 1\n",
    "            if current_depth > self.iterative_depth:\n",
    "                self.display(2, \"Cannot continue, hit iterative depth level\")\n",
    "                forced_deadends += 1\n",
    "                continue\n",
    "            elif self.problem.is_goal(path.end()):\n",
    "                self.display(1, self.num_expanded, \"paths have been expanded and\", \n",
    "                             len(self.frontier), \"paths remain in the frontier\")\n",
    "                self.solution = path\n",
    "                return path\n",
    "            else:\n",
    "                neighs = self.problem.neighbors(path.end())\n",
    "                self.display(3,\"Neighbors are\", neighs)\n",
    "                for arc in reversed(list(neighs)):\n",
    "                    self.add_to_frontier(Path(path,arc), current_depth+1)\n",
    "                self.display(3,\"Frontier:\",self.frontier)\n",
    "\n",
    "        if forced_deadends > 0:\n",
    "            self.iterative_depth += 1\n",
    "            self.display(1,\"Found\",forced_deadends,\"forced dead ends\",\n",
    "                         \"increasing iterative depth to\", self.iterative_depth)\n",
    "            self.add_to_frontier(Path(self.problem.start_node()), 0)\n",
    "            return self.search()\n",
    "        else:                             \n",
    "            self.display(1,\"No (more) solutions. Total of\",self.num_expanded,\"paths expanded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.3\n",
    "Implement a class that performs Iterative Deepening A* Search by extending class Searcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We see an A* search algorithm implementation in `searchGeneric.py`, we use that\n",
    "implementation, then borrow what we have done above re: search method and adapt the bound to be\n",
    "instead based on the lowest \"f value\" removed from the frontier queue during each iteration.\n",
    "\"\"\"\n",
    "\n",
    "class IterativeDeepeningAStarSearcher(Searcher):\n",
    "    def __init__(self, problem):\n",
    "        self.problem = problem\n",
    "        self.initialize_frontier()\n",
    "        self.num_expanded = 0\n",
    "\n",
    "        initial = Path(problem.start_node())\n",
    "        self.iterative_f_value_depth = initial.cost + self.problem.heuristic(initial.end())\n",
    "        self.add_to_frontier(initial, self.iterative_f_value_depth)\n",
    "\n",
    "    def initialize_frontier(self):\n",
    "        self.frontier = FrontierPQ()\n",
    "\n",
    "    def empty_frontier(self):\n",
    "        return self.frontier.empty()\n",
    "\n",
    "    def add_to_frontier(self,path,f_value):\n",
    "        self.frontier.add(path, f_value)\n",
    "    \n",
    "    def search(self):\n",
    "        forced_deadends = 0 \n",
    "        \"\"\" \n",
    "            number of popped nodes in the frontier disregarded due to iterative depth, used\n",
    "            to decide wether to bump the iterative depth of the search, or wave hands re: no solution found\n",
    "        \"\"\"\n",
    "        \n",
    "        min_forced_deadend_f_value = None\n",
    "        \"\"\" \n",
    "            minimum \"f value\" of popped frontier paths due to meeting the forced iterative depth, used\n",
    "            to decide next iterations iterative f value depth.\n",
    "        \"\"\"\n",
    "        def set_min_forced_deadend_f_value(candidate_f_value: int) -> None:\n",
    "            nonlocal min_forced_deadend_f_value\n",
    "            if min_forced_deadend_f_value is None:\n",
    "                min_forced_deadend_f_value = candidate_f_value\n",
    "                return\n",
    "            min_forced_deadend_f_value = min(min_forced_deadend_f_value, candidate_f_value)\n",
    "        \n",
    "        while not self.empty_frontier():\n",
    "            path = self.frontier.pop()\n",
    "            f_value = path.cost + self.problem.heuristic(path.end())\n",
    "            \n",
    "            self.display(2, \"Expanding:\",path,\"f value level: \", min_forced_deadend_f_value,\"(cost:\",path.cost,\")\")\n",
    "            self.num_expanded += 1\n",
    "            if f_value > self.iterative_f_value_depth:\n",
    "                self.display(2, \"Cannot continue, hit iterative f value depth level\")\n",
    "                forced_deadends += 1\n",
    "                set_min_forced_deadend_f_value(f_value)\n",
    "                continue\n",
    "            elif self.problem.is_goal(path.end()):\n",
    "                self.display(1, self.num_expanded, \"paths have been expanded and\", \n",
    "                             len(self.frontier), \"paths remain in the frontier\")\n",
    "                self.solution = path\n",
    "                return path\n",
    "            else:\n",
    "                neighs = self.problem.neighbors(path.end())\n",
    "                self.display(3,\"Neighbors are\", neighs)\n",
    "                for arc in reversed(list(neighs)):\n",
    "                    self.add_to_frontier(Path(path,arc), f_value)\n",
    "                self.display(3,\"Frontier:\",self.frontier)\n",
    "\n",
    "        if forced_deadends > 0:\n",
    "            self.iterative_f_value_depth = min_forced_deadend_f_value\n",
    "            self.display(1,\"Found\",forced_deadends,\"forced dead ends\",\n",
    "                         \"increasing iterative f value depth to\", self.iterative_f_value_depth)\n",
    "            self.add_to_frontier(Path(self.problem.start_node()), min_forced_deadend_f_value)\n",
    "            return self.search()\n",
    "        else:                             \n",
    "            self.display(1,\"No (more) solutions. Total of\",self.num_expanded,\"paths expanded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.4\n",
    "Implement a class that performs Uniform Cost Search by extending class Searcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformCostSearcher(Searcher):\n",
    "    def initialize_frontier(self):\n",
    "        self.frontier = FrontierPQ()\n",
    "\n",
    "    def empty_frontier(self):\n",
    "        return self.frontier.empty()\n",
    "\n",
    "    def add_to_frontier(self, path):\n",
    "        self.frontier.add(path, path.cost + self.problem.heuristic(path.end()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.5\n",
    "\n",
    "Run Breadth First Search (BFS), Iterative Deepenining Search (IDS), Iterative Deepening A* Search (IDA\\*S), and Uniform Cost Search (UCS) algorithms on each of the 5 start states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "\n",
    "\"\"\"\n",
    "    Added this utility to contain the run time of algorithms\n",
    "    programmatically.\n",
    "\"\"\"\n",
    "class timeout:\n",
    "    def __init__(self):\n",
    "        self.seconds = 30\n",
    "    def handle_timeout(self, signum, frame):\n",
    "        raise TimeoutError()\n",
    "    def __enter__(self):\n",
    "        signal.signal(signal.SIGALRM, self.handle_timeout)\n",
    "        signal.alarm(self.seconds)\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        signal.alarm(0)\n",
    "\n",
    "def handle_timeout(searcher):\n",
    "    try:\n",
    "        with timeout():\n",
    "            searcher.search()\n",
    "    except TimeoutError:\n",
    "        print(\"... TIMEOUT\", searcher.num_expanded, \"paths have been expanded and\", \n",
    "                             len(searcher.frontier), \"paths remain in the frontier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "Starting Position:  [[2, 3, 7, 4], [1, 6, 11, 8], [5, 10, 0, 12], [9, 13, 14, 15]]\n",
      "- Breadth First Search: 243079 paths have been expanded and 543549 paths remain in the frontier\n",
      "- Iterative Deepening Search: Found 4 forced dead ends increasing iterative depth to 1\n",
      "Found 14 forced dead ends increasing iterative depth to 2\n",
      "Found 46 forced dead ends increasing iterative depth to 3\n",
      "Found 150 forced dead ends increasing iterative depth to 4\n",
      "Found 486 forced dead ends increasing iterative depth to 5\n",
      "Found 1574 forced dead ends increasing iterative depth to 6\n",
      "Found 5094 forced dead ends increasing iterative depth to 7\n",
      "Found 16486 forced dead ends increasing iterative depth to 8\n",
      "Found 53350 forced dead ends increasing iterative depth to 9\n",
      "Found 172646 forced dead ends increasing iterative depth to 10\n",
      "393280 paths have been expanded and 11 paths remain in the frontier\n",
      "- Iterative Deepening A Start Search: Found 4 forced dead ends increasing iterative depth to 1\n",
      "Found 14 forced dead ends increasing iterative depth to 2\n",
      "Found 46 forced dead ends increasing iterative depth to 3\n",
      "Found 150 forced dead ends increasing iterative depth to 4\n",
      "Found 486 forced dead ends increasing iterative depth to 5\n",
      "Found 1574 forced dead ends increasing iterative depth to 6\n",
      "Found 5094 forced dead ends increasing iterative depth to 7\n",
      "Found 16486 forced dead ends increasing iterative depth to 8\n",
      "Found 53350 forced dead ends increasing iterative depth to 9\n",
      "Found 172646 forced dead ends increasing iterative depth to 10\n",
      "393280 paths have been expanded and 11 paths remain in the frontier\n",
      "- Uniform Cost Search: 73 paths have been expanded and 153 paths remain in the frontier\n",
      "=========\n",
      "Starting Position:  [[2, 7, 11, 4], [6, 3, 12, 0], [1, 5, 15, 8], [9, 10, 13, 14]]\n",
      "- Breadth First Search: ... TIMEOUT 311547 paths have been expanded and 696635 paths remain in the frontier\n",
      "- Iterative Deepening Search: Found 3 forced dead ends increasing iterative depth to 1\n",
      "Found 9 forced dead ends increasing iterative depth to 2\n",
      "Found 29 forced dead ends increasing iterative depth to 3\n",
      "Found 93 forced dead ends increasing iterative depth to 4\n",
      "Found 301 forced dead ends increasing iterative depth to 5\n",
      "Found 973 forced dead ends increasing iterative depth to 6\n",
      "Found 3149 forced dead ends increasing iterative depth to 7\n",
      "Found 10189 forced dead ends increasing iterative depth to 8\n",
      "Found 32973 forced dead ends increasing iterative depth to 9\n",
      "Found 106701 forced dead ends increasing iterative depth to 10\n",
      "Found 345293 forced dead ends increasing iterative depth to 11\n",
      "Found 1117389 forced dead ends increasing iterative depth to 12\n",
      "... TIMEOUT 3373100 paths have been expanded and 12 paths remain in the frontier\n",
      "- Iterative Deepening A Start Search: Found 3 forced dead ends increasing iterative depth to 1\n",
      "Found 9 forced dead ends increasing iterative depth to 2\n",
      "Found 29 forced dead ends increasing iterative depth to 3\n",
      "Found 93 forced dead ends increasing iterative depth to 4\n",
      "Found 301 forced dead ends increasing iterative depth to 5\n",
      "Found 973 forced dead ends increasing iterative depth to 6\n",
      "Found 3149 forced dead ends increasing iterative depth to 7\n",
      "Found 10189 forced dead ends increasing iterative depth to 8\n",
      "Found 32973 forced dead ends increasing iterative depth to 9\n",
      "Found 106701 forced dead ends increasing iterative depth to 10\n",
      "Found 345293 forced dead ends increasing iterative depth to 11\n",
      "Found 1117389 forced dead ends increasing iterative depth to 12\n",
      "... TIMEOUT 3372556 paths have been expanded and 20 paths remain in the frontier\n",
      "- Uniform Cost Search: 32766 paths have been expanded and 65702 paths remain in the frontier\n",
      "=========\n",
      "Starting Position:  [[2, 7, 11, 4], [6, 3, 12, 0], [1, 5, 15, 14], [9, 10, 8, 13]]\n",
      "- Breadth First Search: ... TIMEOUT 303752 paths have been expanded and 679202 paths remain in the frontier\n",
      "- Iterative Deepening Search: Found 3 forced dead ends increasing iterative depth to 1\n",
      "Found 9 forced dead ends increasing iterative depth to 2\n",
      "Found 29 forced dead ends increasing iterative depth to 3\n",
      "Found 93 forced dead ends increasing iterative depth to 4\n",
      "Found 301 forced dead ends increasing iterative depth to 5\n",
      "Found 973 forced dead ends increasing iterative depth to 6\n",
      "Found 3149 forced dead ends increasing iterative depth to 7\n",
      "Found 10189 forced dead ends increasing iterative depth to 8\n",
      "Found 32973 forced dead ends increasing iterative depth to 9\n",
      "Found 106701 forced dead ends increasing iterative depth to 10\n",
      "Found 345293 forced dead ends increasing iterative depth to 11\n",
      "Found 1117389 forced dead ends increasing iterative depth to 12\n",
      "... TIMEOUT 3367444 paths have been expanded and 12 paths remain in the frontier\n",
      "- Iterative Deepening A Start Search: Found 3 forced dead ends increasing iterative depth to 1\n",
      "Found 9 forced dead ends increasing iterative depth to 2\n",
      "Found 29 forced dead ends increasing iterative depth to 3\n",
      "Found 93 forced dead ends increasing iterative depth to 4\n",
      "Found 301 forced dead ends increasing iterative depth to 5\n",
      "Found 973 forced dead ends increasing iterative depth to 6\n",
      "Found 3149 forced dead ends increasing iterative depth to 7\n",
      "Found 10189 forced dead ends increasing iterative depth to 8\n",
      "Found 32973 forced dead ends increasing iterative depth to 9\n",
      "Found 106701 forced dead ends increasing iterative depth to 10\n",
      "Found 345293 forced dead ends increasing iterative depth to 11\n",
      "Found 1117389 forced dead ends increasing iterative depth to 12\n",
      "... TIMEOUT 3374770 paths have been expanded and 13 paths remain in the frontier\n",
      "- Uniform Cost Search: ... TIMEOUT 381325 paths have been expanded and 731644 paths remain in the frontier\n",
      "=========\n",
      "Starting Position:  [[7, 11, 12, 4], [2, 3, 14, 1], [6, 5, 13, 8], [9, 10, 15, 0]]\n",
      "- Breadth First Search: ... TIMEOUT 312022 paths have been expanded and 697692 paths remain in the frontier\n",
      "- Iterative Deepening Search: Found 2 forced dead ends increasing iterative depth to 1\n",
      "Found 6 forced dead ends increasing iterative depth to 2\n",
      "Found 18 forced dead ends increasing iterative depth to 3\n",
      "Found 58 forced dead ends increasing iterative depth to 4\n",
      "Found 186 forced dead ends increasing iterative depth to 5\n",
      "Found 602 forced dead ends increasing iterative depth to 6\n",
      "Found 1946 forced dead ends increasing iterative depth to 7\n",
      "Found 6298 forced dead ends increasing iterative depth to 8\n",
      "Found 20378 forced dead ends increasing iterative depth to 9\n",
      "Found 65946 forced dead ends increasing iterative depth to 10\n",
      "Found 213402 forced dead ends increasing iterative depth to 11\n",
      "Found 690586 forced dead ends increasing iterative depth to 12\n",
      "... TIMEOUT 3350332 paths have been expanded and 17 paths remain in the frontier\n",
      "- Iterative Deepening A Start Search: Found 2 forced dead ends increasing iterative depth to 1\n",
      "Found 6 forced dead ends increasing iterative depth to 2\n",
      "Found 18 forced dead ends increasing iterative depth to 3\n",
      "Found 58 forced dead ends increasing iterative depth to 4\n",
      "Found 186 forced dead ends increasing iterative depth to 5\n",
      "Found 602 forced dead ends increasing iterative depth to 6\n",
      "Found 1946 forced dead ends increasing iterative depth to 7\n",
      "Found 6298 forced dead ends increasing iterative depth to 8\n",
      "Found 20378 forced dead ends increasing iterative depth to 9\n",
      "Found 65946 forced dead ends increasing iterative depth to 10\n",
      "Found 213402 forced dead ends increasing iterative depth to 11\n",
      "Found 690586 forced dead ends increasing iterative depth to 12\n",
      "... TIMEOUT 3358835 paths have been expanded and 15 paths remain in the frontier\n",
      "- Uniform Cost Search: ... TIMEOUT 404823 paths have been expanded and 779601 paths remain in the frontier\n",
      "=========\n",
      "Starting Position:  [[7, 11, 12, 4], [2, 3, 8, 14], [10, 0, 5, 1], [6, 9, 13, 15]]\n",
      "- Breadth First Search: ... TIMEOUT 303481 paths have been expanded and 678616 paths remain in the frontier\n",
      "- Iterative Deepening Search: Found 4 forced dead ends increasing iterative depth to 1\n",
      "Found 14 forced dead ends increasing iterative depth to 2\n",
      "Found 46 forced dead ends increasing iterative depth to 3\n",
      "Found 150 forced dead ends increasing iterative depth to 4\n",
      "Found 486 forced dead ends increasing iterative depth to 5\n",
      "Found 1574 forced dead ends increasing iterative depth to 6\n",
      "Found 5094 forced dead ends increasing iterative depth to 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16486 forced dead ends increasing iterative depth to 8\n",
      "Found 53350 forced dead ends increasing iterative depth to 9\n",
      "Found 172646 forced dead ends increasing iterative depth to 10\n",
      "Found 558694 forced dead ends increasing iterative depth to 11\n",
      "... TIMEOUT 3359713 paths have been expanded and 8 paths remain in the frontier\n",
      "- Iterative Deepening A Start Search: Found 4 forced dead ends increasing iterative depth to 1\n",
      "Found 14 forced dead ends increasing iterative depth to 2\n",
      "Found 46 forced dead ends increasing iterative depth to 3\n",
      "Found 150 forced dead ends increasing iterative depth to 4\n",
      "Found 486 forced dead ends increasing iterative depth to 5\n",
      "Found 1574 forced dead ends increasing iterative depth to 6\n",
      "Found 5094 forced dead ends increasing iterative depth to 7\n",
      "Found 16486 forced dead ends increasing iterative depth to 8\n",
      "Found 53350 forced dead ends increasing iterative depth to 9\n",
      "Found 172646 forced dead ends increasing iterative depth to 10\n",
      "Found 558694 forced dead ends increasing iterative depth to 11\n",
      "... TIMEOUT 3359818 paths have been expanded and 6 paths remain in the frontier\n",
      "- Uniform Cost Search: ... TIMEOUT 413838 paths have been expanded and 761956 paths remain in the frontier\n"
     ]
    }
   ],
   "source": [
    "# optimal path cost: 10\n",
    "start10 = [[2, 3, 7, 4],\n",
    "           [1, 6, 11, 8],\n",
    "           [5, 10, 0, 12],\n",
    "           [9, 13, 14, 15]]\n",
    "\n",
    "# optimal path cost: 24\n",
    "start24 = [[2, 7, 11, 4],\n",
    "           [6, 3, 12, 0],\n",
    "           [1, 5, 15, 8],\n",
    "           [9, 10, 13, 14]]\n",
    "\n",
    "# optimal path cost: 30\n",
    "start30 = [[2, 7, 11, 4],\n",
    "           [6, 3, 12, 0],\n",
    "           [1, 5, 15, 14],\n",
    "           [9, 10, 8, 13]]\n",
    "\n",
    "# optimal path cost: 36\n",
    "start36 = [[7, 11, 12, 4],\n",
    "           [2, 3, 14, 1],\n",
    "           [6, 5, 13, 8],\n",
    "           [9, 10, 15, 0]]\n",
    "\n",
    "# optimal path cost: 41\n",
    "start41 = [[7, 11, 12, 4],\n",
    "           [2, 3, 8, 14],\n",
    "           [10, 0, 5, 1],\n",
    "           [6, 9, 13, 15]]\n",
    "\n",
    "for start in [start10, start24, start30, start36, start41]:\n",
    "    print('=========')\n",
    "    print('Starting Position: ', start)\n",
    "    print('- Breadth First Search: ', end = '')\n",
    "    handle_timeout(BreadthFirstSearcher(GameFifteenProblem(start, goal)))\n",
    "    print('- Iterative Deepening Search: ', end = '')\n",
    "    handle_timeout(IterativeDeepeningSearcher(GameFifteenProblem(start, goal)))\n",
    "    print('- Iterative Deepening A Start Search: ', end = '')\n",
    "    handle_timeout(IterativeDeepeningSearcher(GameFifteenProblem(start, goal)))\n",
    "    print('- Uniform Cost Search: ', end = '')\n",
    "    handle_timeout(UniformCostSearcher(GameFifteenProblem(start, goal)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each case, record in the table below the number of nodes generated during the search. If the algorithm runs out of memory or the number of nodes in the frontier exceeds 1 million items, just write “Mem” in your table. If the code runs for five minutes without producing output, terminate the process and write “Time” in your table.\n",
    "\n",
    "*Tip: To edit the table double click the cell below.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Algorithm | 10      | 24      | 30      | 36      | 41      |\n",
    "|-----------|---------|---------|---------|---------|---------|\n",
    "|BFS        | #       | #       | #       | #       | #       |\n",
    "|A*         | #       | #       | #       | #       | #       |\n",
    "|IDS        | #       | #       | #       | #       | #       |\n",
    "|IDA\\*S     | #       | #       | #       | #       | #       |\n",
    "|UCS        | #       | #       | #       | #       | #       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the time and space efficiency of these four algorithms, comment on the results in the table."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Deceptive Starting States [3 marks]\n",
    "\n",
    "#### Task 3.1 \n",
    "\n",
    "Run IDA* on the starting states below and report the number of the expanded nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "start37_1 = [[7, 11, 12, 4],\n",
    "             [2, 3, 14, 1],\n",
    "             [6, 5, 13, 0],\n",
    "             [9, 10, 15, 8]]\n",
    "\n",
    "start37_2 = [[7, 11, 12, 4],\n",
    "             [2, 3, 8, 14],\n",
    "             [6, 0, 1, 15],\n",
    "             [9, 5, 10, 13]]\n",
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3.2\n",
    "\n",
    "Explain why there is a difference between the number of the expanded nodes for these starting states if their costs of the optimal paths are the same."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4:  Constraint Satisfaction Problem [5 marks]\n",
    "\n",
    "This part of the assignment is based on another puzzle called Sudoku. The game consists of 9x9 grid with a few cells filled in with digits. The objective of the game is to fill the remaining cells so that each column, each row, and each of the nine 3×3 sub-grids contain all of the digits from 1 to 9.\n",
    "\n",
    "The start state of the puzzle is defined as a multidimensional array of numbers, where 0 represents empty cells, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [[9, 5, 0, 8, 2, 7, 3, 0, 0],\n",
    "        [0, 8, 0, 1, 4, 0, 0, 5, 0],\n",
    "        [0, 1, 0, 5, 9, 0, 0, 0, 0],\n",
    "        [8, 3, 0, 0, 0, 0, 0, 7, 5],\n",
    "        [1, 6, 9, 7, 5, 2, 4, 3, 0],\n",
    "        [0, 7, 0, 0, 8, 0, 0, 6, 0],\n",
    "        [0, 9, 1, 0, 6, 0, 8, 4, 0],\n",
    "        [7, 0, 8, 0, 3, 1, 0, 0, 6],\n",
    "        [6, 2, 0, 4, 7, 8, 0, 9, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tip: If you have problems with understanding how to implement constrains take a look at cspExamples.py and cspExamplesQueens.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4.1\n",
    "\n",
    "Write the code that defines constraint(s) and a function grid_to_csp that returns a CSP for a Sudoku puzzle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_to_csp(grid):\n",
    "    \"\"\"returns a soduko constraint satisfaction problem\"\"\"\n",
    "    \n",
    "    def cross(A,B): return [a+b for a in A for b in B]\n",
    "    rows, cols = 'ABCDEFGHI', '123456789'\n",
    "    \n",
    "    \"\"\"a unit generalises cells that are collections defined by row, column or box\"\"\"\n",
    "    unit_list = (\n",
    "            [cross(rows, col) for col in cols] +\n",
    "            [cross(row, cols) for row in rows] +\n",
    "            [cross(box_rows, box_cols) for box_rows in ('ABC','DEF','GHI') for box_cols in ('123','456','789')]\n",
    "    )\n",
    "\n",
    "    domains = {}\n",
    "    for row_index, row in enumerate(grid):\n",
    "        for col_index, value in enumerate(row):\n",
    "            square_index = rows[row_index] + cols[col_index]\n",
    "\n",
    "            match value:\n",
    "              case 0: # we interpret zero's as being anything\n",
    "                  domains[square_index] = Variable(square_index, {1, 2, 3, 4, 5, 6, 7, 8, 9})\n",
    "              case _: # anything else is the starter value hence reducing the domain to just that value\n",
    "                  domains[square_index] = Variable(square_index, {value})\n",
    "\n",
    "    constraints = []\n",
    "    for square_index, variable in domains.items():\n",
    "        must_be_different_to = set()\n",
    "        for unit in [unit for unit in unit_list if square_index in unit]:\n",
    "            must_be_different_to = must_be_different_to | set([cell for cell in unit])\n",
    "        must_be_different_to.remove(square_index)\n",
    "                \n",
    "        def not_equal(x,y): return x != y\n",
    "        for square in must_be_different_to:\n",
    "            constraints.append(Constraint([variable, domains[square]], not_equal))\n",
    "\n",
    "    \n",
    "    return CSP(\"soduku\", {variable for _, variable in domains.items()}, constraints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4.2\n",
    "\n",
    "Write the code that solves Sudoku csp using a search algorithms of your choice, print the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CSP(soduku, {E3, B9, C2, C3, C1, C4, E2, D5, C5, D3, D4, C6, C7, C8, C9, D1, D2, D6, D9, E1, D7, D8, E9, F1, A6, I3, I4, B5, B4, I2, B2, B3, F2, F3, B1, F4, A9, G5, G1, A7, A8, G4, A4, G2, G3, A5, I8, I7, I9, I6, I5, H7, H6, F5, F9, F6, F8, F7, G6, G7, G8, H2, G9, H1, H3, I1, H4, H9, H8, H5, A1, A2, A3, B6, B7, E7, E8, E6, B8, E4, E5}, ['ne[A1, A6]', 'ne[A1, F1]', 'ne[A1, G1]', 'ne[A1, A2]', 'ne[A1, H1]', 'ne[A1, A7]', 'ne[A1, E1]', 'ne[A1, C1]', 'ne[A1, B3]', 'ne[A1, B2]', 'ne[A1, D1]', 'ne[A1, A4]', 'ne[A1, A8]', 'ne[A1, C3]', 'ne[A1, A5]', 'ne[A1, I1]', 'ne[A1, A9]', 'ne[A1, B1]', 'ne[A1, A3]', 'ne[A1, C2]', 'ne[A2, A6]', 'ne[A2, I2]', 'ne[A2, H2]', 'ne[A2, A7]', 'ne[A2, F2]', 'ne[A2, D2]', 'ne[A2, G2]', 'ne[A2, B2]', 'ne[A2, B3]', 'ne[A2, C1]', 'ne[A2, A8]', 'ne[A2, A4]', 'ne[A2, C3]', 'ne[A2, A1]', 'ne[A2, A5]', 'ne[A2, A9]', 'ne[A2, E2]', 'ne[A2, B1]', 'ne[A2, A3]', 'ne[A2, C2]', 'ne[A3, A6]', 'ne[A3, A2]', 'ne[A3, G3]', 'ne[A3, A7]', 'ne[A3, H3]', 'ne[A3, F3]', 'ne[A3, B3]', 'ne[A3, B2]', 'ne[A3, C1]', 'ne[A3, A8]', 'ne[A3, A4]', 'ne[A3, C3]', 'ne[A3, A1]', 'ne[A3, D3]', 'ne[A3, A5]', 'ne[A3, A9]', 'ne[A3, E3]', 'ne[A3, I3]', 'ne[A3, B1]', 'ne[A3, C2]', 'ne[A4, H4]', 'ne[A4, E4]', 'ne[A4, C6]', 'ne[A4, A6]', 'ne[A4, A2]', 'ne[A4, B4]', 'ne[A4, I4]', 'ne[A4, B5]', 'ne[A4, A7]', 'ne[A4, C4]', 'ne[A4, F4]', 'ne[A4, D4]', 'ne[A4, A8]', 'ne[A4, C5]', 'ne[A4, A1]', 'ne[A4, A5]', 'ne[A4, A9]', 'ne[A4, B6]', 'ne[A4, G4]', 'ne[A4, A3]', 'ne[A5, F5]', 'ne[A5, C6]', 'ne[A5, A6]', 'ne[A5, A2]', 'ne[A5, D5]', 'ne[A5, B4]', 'ne[A5, I5]', 'ne[A5, B5]', 'ne[A5, G5]', 'ne[A5, A7]', 'ne[A5, C4]', 'ne[A5, E5]', 'ne[A5, A8]', 'ne[A5, A4]', 'ne[A5, C5]', 'ne[A5, A1]', 'ne[A5, A9]', 'ne[A5, H5]', 'ne[A5, B6]', 'ne[A5, A3]', 'ne[A6, G6]', 'ne[A6, C6]', 'ne[A6, A2]', 'ne[A6, B4]', 'ne[A6, B5]', 'ne[A6, H6]', 'ne[A6, A7]', 'ne[A6, C4]', 'ne[A6, D6]', 'ne[A6, F6]', 'ne[A6, I6]', 'ne[A6, A4]', 'ne[A6, A8]', 'ne[A6, C5]', 'ne[A6, A1]', 'ne[A6, A5]', 'ne[A6, A9]', 'ne[A6, E6]', 'ne[A6, B6]', 'ne[A6, A3]', 'ne[A7, I7]', 'ne[A7, C9]', 'ne[A7, A6]', 'ne[A7, A2]', 'ne[A7, C8]', 'ne[A7, C7]', 'ne[A7, E7]', 'ne[A7, G7]', 'ne[A7, B9]', 'ne[A7, B7]', 'ne[A7, A4]', 'ne[A7, A8]', 'ne[A7, B8]', 'ne[A7, H7]', 'ne[A7, A1]', 'ne[A7, A5]', 'ne[A7, A9]', 'ne[A7, F7]', 'ne[A7, A3]', 'ne[A7, D7]', 'ne[A8, F8]', 'ne[A8, C9]', 'ne[A8, A6]', 'ne[A8, D8]', 'ne[A8, A2]', 'ne[A8, C8]', 'ne[A8, C7]', 'ne[A8, A7]', 'ne[A8, G8]', 'ne[A8, B9]', 'ne[A8, H8]', 'ne[A8, A4]', 'ne[A8, B8]', 'ne[A8, B7]', 'ne[A8, A1]', 'ne[A8, A5]', 'ne[A8, A9]', 'ne[A8, I8]', 'ne[A8, E8]', 'ne[A8, A3]', 'ne[A9, C9]', 'ne[A9, A6]', 'ne[A9, A2]', 'ne[A9, C8]', 'ne[A9, H9]', 'ne[A9, C7]', 'ne[A9, D9]', 'ne[A9, A7]', 'ne[A9, B9]', 'ne[A9, A8]', 'ne[A9, A4]', 'ne[A9, E9]', 'ne[A9, B7]', 'ne[A9, B8]', 'ne[A9, A1]', 'ne[A9, I9]', 'ne[A9, F9]', 'ne[A9, G9]', 'ne[A9, A5]', 'ne[A9, A3]', 'ne[B1, F1]', 'ne[B1, G1]', 'ne[B1, A2]', 'ne[B1, B4]', 'ne[B1, H1]', 'ne[B1, B5]', 'ne[B1, E1]', 'ne[B1, C1]', 'ne[B1, B3]', 'ne[B1, B2]', 'ne[B1, B9]', 'ne[B1, D1]', 'ne[B1, B7]', 'ne[B1, B8]', 'ne[B1, C3]', 'ne[B1, A1]', 'ne[B1, I1]', 'ne[B1, B6]', 'ne[B1, A3]', 'ne[B1, C2]', 'ne[B2, A2]', 'ne[B2, B4]', 'ne[B2, I2]', 'ne[B2, B5]', 'ne[B2, H2]', 'ne[B2, F2]', 'ne[B2, D2]', 'ne[B2, G2]', 'ne[B2, B3]', 'ne[B2, B9]', 'ne[B2, C1]', 'ne[B2, B7]', 'ne[B2, B8]', 'ne[B2, C3]', 'ne[B2, A1]', 'ne[B2, E2]', 'ne[B2, B1]', 'ne[B2, B6]', 'ne[B2, A3]', 'ne[B2, C2]', 'ne[B3, A2]', 'ne[B3, G3]', 'ne[B3, B4]', 'ne[B3, B5]', 'ne[B3, H3]', 'ne[B3, F3]', 'ne[B3, B2]', 'ne[B3, B9]', 'ne[B3, C1]', 'ne[B3, B7]', 'ne[B3, C3]', 'ne[B3, B8]', 'ne[B3, A1]', 'ne[B3, D3]', 'ne[B3, E3]', 'ne[B3, I3]', 'ne[B3, B1]', 'ne[B3, B6]', 'ne[B3, A3]', 'ne[B3, C2]', 'ne[B4, H4]', 'ne[B4, E4]', 'ne[B4, C6]', 'ne[B4, A6]', 'ne[B4, I4]', 'ne[B4, B5]', 'ne[B4, C4]', 'ne[B4, F4]', 'ne[B4, B3]', 'ne[B4, B2]', 'ne[B4, B9]', 'ne[B4, D4]', 'ne[B4, B7]', 'ne[B4, A4]', 'ne[B4, B8]', 'ne[B4, C5]', 'ne[B4, A5]', 'ne[B4, B1]', 'ne[B4, B6]', 'ne[B4, G4]', 'ne[B5, F5]', 'ne[B5, C6]', 'ne[B5, A6]', 'ne[B5, D5]', 'ne[B5, B4]', 'ne[B5, I5]', 'ne[B5, G5]', 'ne[B5, C4]', 'ne[B5, B3]', 'ne[B5, B2]', 'ne[B5, B9]', 'ne[B5, E5]', 'ne[B5, B7]', 'ne[B5, A4]', 'ne[B5, B8]', 'ne[B5, C5]', 'ne[B5, A5]', 'ne[B5, H5]', 'ne[B5, B1]', 'ne[B5, B6]', 'ne[B6, G6]', 'ne[B6, C6]', 'ne[B6, A6]', 'ne[B6, B4]', 'ne[B6, B5]', 'ne[B6, H6]', 'ne[B6, C4]', 'ne[B6, D6]', 'ne[B6, B3]', 'ne[B6, B2]', 'ne[B6, B9]', 'ne[B6, F6]', 'ne[B6, I6]', 'ne[B6, B7]', 'ne[B6, B8]', 'ne[B6, A4]', 'ne[B6, C5]', 'ne[B6, A5]', 'ne[B6, E6]', 'ne[B6, B1]', 'ne[B7, I7]', 'ne[B7, C9]', 'ne[B7, B4]', 'ne[B7, C8]', 'ne[B7, B5]', 'ne[B7, C7]', 'ne[B7, E7]', 'ne[B7, A7]', 'ne[B7, B3]', 'ne[B7, G7]', 'ne[B7, B2]', 'ne[B7, B9]', 'ne[B7, A8]', 'ne[B7, B8]', 'ne[B7, H7]', 'ne[B7, A9]', 'ne[B7, F7]', 'ne[B7, B1]', 'ne[B7, B6]', 'ne[B7, D7]', 'ne[B8, F8]', 'ne[B8, C9]', 'ne[B8, D8]', 'ne[B8, B4]', 'ne[B8, C8]', 'ne[B8, B5]', 'ne[B8, C7]', 'ne[B8, A7]', 'ne[B8, B3]', 'ne[B8, B2]', 'ne[B8, G8]', 'ne[B8, B9]', 'ne[B8, A8]', 'ne[B8, H8]', 'ne[B8, B7]', 'ne[B8, A9]', 'ne[B8, I8]', 'ne[B8, B1]', 'ne[B8, B6]', 'ne[B8, E8]', 'ne[B9, C9]', 'ne[B9, B4]', 'ne[B9, C8]', 'ne[B9, B5]', 'ne[B9, H9]', 'ne[B9, C7]', 'ne[B9, D9]', 'ne[B9, A7]', 'ne[B9, B3]', 'ne[B9, B2]', 'ne[B9, B7]', 'ne[B9, A8]', 'ne[B9, E9]', 'ne[B9, B8]', 'ne[B9, I9]', 'ne[B9, F9]', 'ne[B9, A9]', 'ne[B9, G9]', 'ne[B9, B1]', 'ne[B9, B6]', 'ne[C1, C9]', 'ne[C1, C6]', 'ne[C1, F1]', 'ne[C1, G1]', 'ne[C1, A2]', 'ne[C1, C8]', 'ne[C1, H1]', 'ne[C1, C7]', 'ne[C1, C4]', 'ne[C1, E1]', 'ne[C1, B3]', 'ne[C1, B2]', 'ne[C1, D1]', 'ne[C1, C3]', 'ne[C1, C5]', 'ne[C1, A1]', 'ne[C1, I1]', 'ne[C1, B1]', 'ne[C1, A3]', 'ne[C1, C2]', 'ne[C2, C9]', 'ne[C2, C6]', 'ne[C2, A2]', 'ne[C2, C8]', 'ne[C2, I2]', 'ne[C2, C7]', 'ne[C2, H2]', 'ne[C2, C4]', 'ne[C2, F2]', 'ne[C2, D2]', 'ne[C2, G2]', 'ne[C2, B2]', 'ne[C2, C1]', 'ne[C2, B3]', 'ne[C2, C3]', 'ne[C2, C5]', 'ne[C2, A1]', 'ne[C2, E2]', 'ne[C2, B1]', 'ne[C2, A3]', 'ne[C3, C9]', 'ne[C3, C6]', 'ne[C3, A2]', 'ne[C3, G3]', 'ne[C3, C8]', 'ne[C3, C7]', 'ne[C3, C4]', 'ne[C3, H3]', 'ne[C3, F3]', 'ne[C3, B3]', 'ne[C3, C1]', 'ne[C3, B2]', 'ne[C3, C5]', 'ne[C3, A1]', 'ne[C3, D3]', 'ne[C3, E3]', 'ne[C3, I3]', 'ne[C3, B1]', 'ne[C3, A3]', 'ne[C3, C2]', 'ne[C4, H4]', 'ne[C4, C9]', 'ne[C4, E4]', 'ne[C4, C6]', 'ne[C4, A6]', 'ne[C4, B4]', 'ne[C4, I4]', 'ne[C4, C8]', 'ne[C4, B5]', 'ne[C4, C7]', 'ne[C4, F4]', 'ne[C4, C1]', 'ne[C4, D4]', 'ne[C4, A4]', 'ne[C4, C3]', 'ne[C4, C5]', 'ne[C4, A5]', 'ne[C4, B6]', 'ne[C4, G4]', 'ne[C4, C2]', 'ne[C5, C9]', 'ne[C5, F5]', 'ne[C5, C6]', 'ne[C5, A6]', 'ne[C5, D5]', 'ne[C5, B4]', 'ne[C5, I5]', 'ne[C5, B5]', 'ne[C5, C8]', 'ne[C5, C7]', 'ne[C5, G5]', 'ne[C5, C4]', 'ne[C5, C1]', 'ne[C5, E5]', 'ne[C5, A4]', 'ne[C5, C3]', 'ne[C5, A5]', 'ne[C5, H5]', 'ne[C5, B6]', 'ne[C5, C2]', 'ne[C6, G6]', 'ne[C6, C9]', 'ne[C6, A6]', 'ne[C6, B4]', 'ne[C6, C8]', 'ne[C6, B5]', 'ne[C6, C7]', 'ne[C6, H6]', 'ne[C6, C4]', 'ne[C6, D6]', 'ne[C6, C1]', 'ne[C6, F6]', 'ne[C6, I6]', 'ne[C6, A4]', 'ne[C6, C3]', 'ne[C6, C5]', 'ne[C6, A5]', 'ne[C6, E6]', 'ne[C6, B6]', 'ne[C6, C2]', 'ne[C7, I7]', 'ne[C7, C9]', 'ne[C7, C6]', 'ne[C7, C8]', 'ne[C7, E7]', 'ne[C7, A7]', 'ne[C7, C4]', 'ne[C7, C1]', 'ne[C7, G7]', 'ne[C7, B9]', 'ne[C7, B7]', 'ne[C7, A8]', 'ne[C7, C3]', 'ne[C7, H7]', 'ne[C7, C5]', 'ne[C7, B8]', 'ne[C7, A9]', 'ne[C7, F7]', 'ne[C7, D7]', 'ne[C7, C2]', 'ne[C8, F8]', 'ne[C8, C9]', 'ne[C8, C6]', 'ne[C8, D8]', 'ne[C8, C7]', 'ne[C8, A7]', 'ne[C8, C4]', 'ne[C8, C1]', 'ne[C8, G8]', 'ne[C8, B9]', 'ne[C8, A8]', 'ne[C8, H8]', 'ne[C8, B7]', 'ne[C8, B8]', 'ne[C8, C3]', 'ne[C8, C5]', 'ne[C8, A9]', 'ne[C8, I8]', 'ne[C8, E8]', 'ne[C8, C2]', 'ne[C9, C6]', 'ne[C9, C8]', 'ne[C9, H9]', 'ne[C9, C7]', 'ne[C9, D9]', 'ne[C9, C4]', 'ne[C9, A7]', 'ne[C9, C1]', 'ne[C9, B9]', 'ne[C9, B7]', 'ne[C9, A8]', 'ne[C9, E9]', 'ne[C9, C3]', 'ne[C9, C5]', 'ne[C9, B8]', 'ne[C9, I9]', 'ne[C9, F9]', 'ne[C9, A9]', 'ne[C9, G9]', 'ne[C9, C2]', 'ne[D1, F1]', 'ne[D1, D8]', 'ne[D1, G1]', 'ne[D1, D5]', 'ne[D1, H1]', 'ne[D1, D9]', 'ne[D1, F3]', 'ne[D1, F2]', 'ne[D1, D2]', 'ne[D1, D6]', 'ne[D1, E1]', 'ne[D1, C1]', 'ne[D1, D4]', 'ne[D1, A1]', 'ne[D1, D3]', 'ne[D1, I1]', 'ne[D1, E3]', 'ne[D1, E2]', 'ne[D1, B1]', 'ne[D1, D7]', 'ne[D2, D8]', 'ne[D2, F1]', 'ne[D2, A2]', 'ne[D2, D5]', 'ne[D2, I2]', 'ne[D2, D9]', 'ne[D2, H2]', 'ne[D2, F3]', 'ne[D2, F2]', 'ne[D2, D6]', 'ne[D2, G2]', 'ne[D2, B2]', 'ne[D2, E1]', 'ne[D2, D4]', 'ne[D2, D1]', 'ne[D2, D3]', 'ne[D2, E3]', 'ne[D2, E2]', 'ne[D2, D7]', 'ne[D2, C2]', 'ne[D3, D8]', 'ne[D3, F1]', 'ne[D3, G3]', 'ne[D3, D5]', 'ne[D3, D9]', 'ne[D3, H3]', 'ne[D3, F3]', 'ne[D3, F2]', 'ne[D3, D2]', 'ne[D3, D6]', 'ne[D3, B3]', 'ne[D3, E1]', 'ne[D3, D4]', 'ne[D3, D1]', 'ne[D3, C3]', 'ne[D3, E3]', 'ne[D3, E2]', 'ne[D3, I3]', 'ne[D3, A3]', 'ne[D3, D7]', 'ne[D4, H4]', 'ne[D4, E4]', 'ne[D4, F5]', 'ne[D4, D8]', 'ne[D4, D5]', 'ne[D4, B4]', 'ne[D4, I4]', 'ne[D4, D9]', 'ne[D4, C4]', 'ne[D4, F4]', 'ne[D4, D2]', 'ne[D4, D6]', 'ne[D4, E5]', 'ne[D4, D1]', 'ne[D4, A4]', 'ne[D4, F6]', 'ne[D4, D3]', 'ne[D4, E6]', 'ne[D4, G4]', 'ne[D4, D7]', 'ne[D5, F5]', 'ne[D5, E4]', 'ne[D5, D8]', 'ne[D5, I5]', 'ne[D5, B5]', 'ne[D5, G5]', 'ne[D5, D9]', 'ne[D5, F4]', 'ne[D5, D2]', 'ne[D5, D6]', 'ne[D5, D4]', 'ne[D5, E5]', 'ne[D5, D1]', 'ne[D5, F6]', 'ne[D5, C5]', 'ne[D5, A5]', 'ne[D5, D3]', 'ne[D5, E6]', 'ne[D5, H5]', 'ne[D5, D7]', 'ne[D6, G6]', 'ne[D6, E4]', 'ne[D6, C6]', 'ne[D6, A6]', 'ne[D6, F5]', 'ne[D6, D8]', 'ne[D6, D5]', 'ne[D6, H6]', 'ne[D6, D9]', 'ne[D6, F4]', 'ne[D6, D2]', 'ne[D6, D4]', 'ne[D6, E5]', 'ne[D6, F6]', 'ne[D6, I6]', 'ne[D6, D1]', 'ne[D6, D3]', 'ne[D6, E6]', 'ne[D6, B6]', 'ne[D6, D7]', 'ne[D7, F8]', 'ne[D7, I7]', 'ne[D7, D8]', 'ne[D7, D5]', 'ne[D7, C7]', 'ne[D7, E7]', 'ne[D7, D9]', 'ne[D7, A7]', 'ne[D7, D2]', 'ne[D7, D6]', 'ne[D7, G7]', 'ne[D7, D4]', 'ne[D7, B7]', 'ne[D7, D1]', 'ne[D7, E9]', 'ne[D7, H7]', 'ne[D7, D3]', 'ne[D7, F9]', 'ne[D7, F7]', 'ne[D7, E8]', 'ne[D8, F8]', 'ne[D8, D5]', 'ne[D8, C8]', 'ne[D8, E7]', 'ne[D8, D9]', 'ne[D8, D2]', 'ne[D8, D6]', 'ne[D8, G8]', 'ne[D8, D4]', 'ne[D8, A8]', 'ne[D8, H8]', 'ne[D8, D1]', 'ne[D8, B8]', 'ne[D8, E9]', 'ne[D8, D3]', 'ne[D8, F9]', 'ne[D8, I8]', 'ne[D8, F7]', 'ne[D8, E8]', 'ne[D8, D7]', 'ne[D9, F8]', 'ne[D9, C9]', 'ne[D9, D8]', 'ne[D9, D5]', 'ne[D9, H9]', 'ne[D9, E7]', 'ne[D9, D2]', 'ne[D9, D6]', 'ne[D9, B9]', 'ne[D9, D4]', 'ne[D9, D1]', 'ne[D9, E9]', 'ne[D9, I9]', 'ne[D9, F9]', 'ne[D9, A9]', 'ne[D9, G9]', 'ne[D9, D3]', 'ne[D9, F7]', 'ne[D9, E8]', 'ne[D9, D7]', 'ne[E1, E4]', 'ne[E1, F1]', 'ne[E1, G1]', 'ne[E1, H1]', 'ne[E1, E7]', 'ne[E1, F3]', 'ne[E1, F2]', 'ne[E1, D2]', 'ne[E1, C1]', 'ne[E1, E5]', 'ne[E1, D1]', 'ne[E1, E9]', 'ne[E1, A1]', 'ne[E1, D3]', 'ne[E1, I1]', 'ne[E1, E3]', 'ne[E1, E2]', 'ne[E1, E6]', 'ne[E1, B1]', 'ne[E1, E8]', 'ne[E2, E4]', 'ne[E2, F1]', 'ne[E2, A2]', 'ne[E2, I2]', 'ne[E2, E7]', 'ne[E2, H2]', 'ne[E2, F3]', 'ne[E2, F2]', 'ne[E2, D2]', 'ne[E2, G2]', 'ne[E2, B2]', 'ne[E2, E1]', 'ne[E2, E5]', 'ne[E2, D1]', 'ne[E2, E9]', 'ne[E2, D3]', 'ne[E2, E3]', 'ne[E2, E6]', 'ne[E2, E8]', 'ne[E2, C2]', 'ne[E3, E4]', 'ne[E3, F1]', 'ne[E3, G3]', 'ne[E3, E7]', 'ne[E3, H3]', 'ne[E3, F3]', 'ne[E3, F2]', 'ne[E3, D2]', 'ne[E3, B3]', 'ne[E3, E1]', 'ne[E3, E5]', 'ne[E3, D1]', 'ne[E3, E9]', 'ne[E3, C3]', 'ne[E3, D3]', 'ne[E3, E2]', 'ne[E3, E6]', 'ne[E3, I3]', 'ne[E3, E8]', 'ne[E3, A3]', 'ne[E4, H4]', 'ne[E4, F5]', 'ne[E4, D5]', 'ne[E4, B4]', 'ne[E4, I4]', 'ne[E4, E7]', 'ne[E4, C4]', 'ne[E4, F4]', 'ne[E4, D6]', 'ne[E4, E1]', 'ne[E4, D4]', 'ne[E4, E5]', 'ne[E4, F6]', 'ne[E4, A4]', 'ne[E4, E9]', 'ne[E4, E3]', 'ne[E4, E2]', 'ne[E4, E6]', 'ne[E4, G4]', 'ne[E4, E8]', 'ne[E5, F5]', 'ne[E5, E4]', 'ne[E5, D5]', 'ne[E5, I5]', 'ne[E5, B5]', 'ne[E5, G5]', 'ne[E5, E7]', 'ne[E5, F4]', 'ne[E5, D6]', 'ne[E5, E1]', 'ne[E5, D4]', 'ne[E5, F6]', 'ne[E5, E9]', 'ne[E5, C5]', 'ne[E5, A5]', 'ne[E5, E3]', 'ne[E5, H5]', 'ne[E5, E2]', 'ne[E5, E6]', 'ne[E5, E8]', 'ne[E6, G6]', 'ne[E6, E4]', 'ne[E6, C6]', 'ne[E6, A6]', 'ne[E6, F5]', 'ne[E6, D5]', 'ne[E6, H6]', 'ne[E6, E7]', 'ne[E6, F4]', 'ne[E6, D6]', 'ne[E6, E1]', 'ne[E6, D4]', 'ne[E6, E5]', 'ne[E6, F6]', 'ne[E6, I6]', 'ne[E6, E9]', 'ne[E6, E3]', 'ne[E6, E2]', 'ne[E6, B6]', 'ne[E6, E8]', 'ne[E7, F8]', 'ne[E7, I7]', 'ne[E7, E4]', 'ne[E7, D8]', 'ne[E7, C7]', 'ne[E7, A7]', 'ne[E7, D9]', 'ne[E7, E1]', 'ne[E7, G7]', 'ne[E7, E5]', 'ne[E7, B7]', 'ne[E7, E9]', 'ne[E7, H7]', 'ne[E7, F9]', 'ne[E7, E3]', 'ne[E7, F7]', 'ne[E7, E2]', 'ne[E7, E6]', 'ne[E7, E8]', 'ne[E7, D7]', 'ne[E8, F8]', 'ne[E8, E4]', 'ne[E8, D8]', 'ne[E8, C8]', 'ne[E8, E7]', 'ne[E8, D9]', 'ne[E8, E1]', 'ne[E8, G8]', 'ne[E8, E5]', 'ne[E8, A8]', 'ne[E8, H8]', 'ne[E8, E9]', 'ne[E8, B8]', 'ne[E8, F9]', 'ne[E8, E3]', 'ne[E8, I8]', 'ne[E8, E2]', 'ne[E8, E6]', 'ne[E8, F7]', 'ne[E8, D7]', 'ne[E9, F8]', 'ne[E9, C9]', 'ne[E9, E4]', 'ne[E9, D8]', 'ne[E9, H9]', 'ne[E9, E7]', 'ne[E9, D9]', 'ne[E9, E1]', 'ne[E9, B9]', 'ne[E9, E5]', 'ne[E9, I9]', 'ne[E9, F9]', 'ne[E9, A9]', 'ne[E9, G9]', 'ne[E9, E3]', 'ne[E9, E2]', 'ne[E9, E6]', 'ne[E9, F7]', 'ne[E9, E8]', 'ne[E9, D7]', 'ne[F1, F8]', 'ne[F1, F5]', 'ne[F1, G1]', 'ne[F1, H1]', 'ne[F1, F3]', 'ne[F1, F2]', 'ne[F1, F4]', 'ne[F1, D2]', 'ne[F1, E1]', 'ne[F1, C1]', 'ne[F1, D1]', 'ne[F1, F6]', 'ne[F1, A1]', 'ne[F1, D3]', 'ne[F1, F9]', 'ne[F1, I1]', 'ne[F1, E3]', 'ne[F1, F7]', 'ne[F1, E2]', 'ne[F1, B1]', 'ne[F2, F8]', 'ne[F2, F5]', 'ne[F2, F1]', 'ne[F2, A2]', 'ne[F2, I2]', 'ne[F2, H2]', 'ne[F2, F3]', 'ne[F2, F4]', 'ne[F2, D2]', 'ne[F2, G2]', 'ne[F2, B2]', 'ne[F2, E1]', 'ne[F2, F6]', 'ne[F2, D1]', 'ne[F2, D3]', 'ne[F2, F9]', 'ne[F2, E3]', 'ne[F2, E2]', 'ne[F2, F7]', 'ne[F2, C2]', 'ne[F3, F8]', 'ne[F3, F5]', 'ne[F3, F1]', 'ne[F3, G3]', 'ne[F3, H3]', 'ne[F3, F2]', 'ne[F3, F4]', 'ne[F3, D2]', 'ne[F3, B3]', 'ne[F3, E1]', 'ne[F3, F6]', 'ne[F3, D1]', 'ne[F3, C3]', 'ne[F3, D3]', 'ne[F3, F9]', 'ne[F3, E3]', 'ne[F3, F7]', 'ne[F3, E2]', 'ne[F3, I3]', 'ne[F3, A3]', 'ne[F4, H4]', 'ne[F4, F8]', 'ne[F4, E4]', 'ne[F4, F5]', 'ne[F4, F1]', 'ne[F4, D5]', 'ne[F4, B4]', 'ne[F4, I4]', 'ne[F4, C4]', 'ne[F4, F3]', 'ne[F4, F2]', 'ne[F4, D6]', 'ne[F4, D4]', 'ne[F4, E5]', 'ne[F4, F6]', 'ne[F4, A4]', 'ne[F4, F9]', 'ne[F4, E6]', 'ne[F4, F7]', 'ne[F4, G4]', 'ne[F5, F8]', 'ne[F5, E4]', 'ne[F5, F1]', 'ne[F5, D5]', 'ne[F5, I5]', 'ne[F5, B5]', 'ne[F5, G5]', 'ne[F5, F3]', 'ne[F5, F2]', 'ne[F5, F4]', 'ne[F5, D6]', 'ne[F5, D4]', 'ne[F5, E5]', 'ne[F5, F6]', 'ne[F5, C5]', 'ne[F5, A5]', 'ne[F5, F9]', 'ne[F5, E6]', 'ne[F5, H5]', 'ne[F5, F7]', 'ne[F6, F8]', 'ne[F6, G6]', 'ne[F6, F5]', 'ne[F6, C6]', 'ne[F6, A6]', 'ne[F6, E4]', 'ne[F6, F1]', 'ne[F6, D5]', 'ne[F6, H6]', 'ne[F6, F3]', 'ne[F6, F2]', 'ne[F6, F4]', 'ne[F6, D6]', 'ne[F6, D4]', 'ne[F6, E5]', 'ne[F6, I6]', 'ne[F6, F9]', 'ne[F6, E6]', 'ne[F6, F7]', 'ne[F6, B6]', 'ne[F7, F8]', 'ne[F7, I7]', 'ne[F7, F5]', 'ne[F7, F1]', 'ne[F7, D8]', 'ne[F7, C7]', 'ne[F7, E7]', 'ne[F7, A7]', 'ne[F7, D9]', 'ne[F7, F3]', 'ne[F7, F2]', 'ne[F7, F4]', 'ne[F7, G7]', 'ne[F7, B7]', 'ne[F7, F6]', 'ne[F7, E9]', 'ne[F7, H7]', 'ne[F7, F9]', 'ne[F7, E8]', 'ne[F7, D7]', 'ne[F8, F5]', 'ne[F8, D8]', 'ne[F8, F1]', 'ne[F8, C8]', 'ne[F8, E7]', 'ne[F8, D9]', 'ne[F8, F3]', 'ne[F8, F2]', 'ne[F8, F4]', 'ne[F8, G8]', 'ne[F8, A8]', 'ne[F8, H8]', 'ne[F8, F6]', 'ne[F8, B8]', 'ne[F8, E9]', 'ne[F8, F9]', 'ne[F8, I8]', 'ne[F8, F7]', 'ne[F8, E8]', 'ne[F8, D7]', 'ne[F9, F8]', 'ne[F9, C9]', 'ne[F9, F5]', 'ne[F9, F1]', 'ne[F9, D8]', 'ne[F9, H9]', 'ne[F9, E7]', 'ne[F9, D9]', 'ne[F9, F3]', 'ne[F9, F2]', 'ne[F9, F4]', 'ne[F9, B9]', 'ne[F9, F6]', 'ne[F9, E9]', 'ne[F9, I9]', 'ne[F9, A9]', 'ne[F9, G9]', 'ne[F9, F7]', 'ne[F9, E8]', 'ne[F9, D7]', 'ne[G1, G6]', 'ne[G1, F1]', 'ne[G1, G3]', 'ne[G1, H1]', 'ne[G1, G5]', 'ne[G1, H2]', 'ne[G1, H3]', 'ne[G1, E1]', 'ne[G1, C1]', 'ne[G1, G2]', 'ne[G1, G7]', 'ne[G1, G8]', 'ne[G1, D1]', 'ne[G1, A1]', 'ne[G1, I1]', 'ne[G1, G9]', 'ne[G1, B1]', 'ne[G1, I3]', 'ne[G1, G4]', 'ne[G1, I2]', 'ne[G2, G6]', 'ne[G2, A2]', 'ne[G2, G1]', 'ne[G2, G3]', 'ne[G2, I2]', 'ne[G2, H1]', 'ne[G2, G5]', 'ne[G2, H2]', 'ne[G2, H3]', 'ne[G2, F2]', 'ne[G2, D2]', 'ne[G2, B2]', 'ne[G2, G7]', 'ne[G2, G8]', 'ne[G2, I1]', 'ne[G2, G9]', 'ne[G2, E2]', 'ne[G2, I3]', 'ne[G2, G4]', 'ne[G2, C2]', 'ne[G3, G6]', 'ne[G3, G1]', 'ne[G3, H1]', 'ne[G3, G5]', 'ne[G3, H2]', 'ne[G3, H3]', 'ne[G3, F3]', 'ne[G3, B3]', 'ne[G3, G2]', 'ne[G3, G7]', 'ne[G3, G8]', 'ne[G3, C3]', 'ne[G3, D3]', 'ne[G3, I1]', 'ne[G3, G9]', 'ne[G3, E3]', 'ne[G3, I3]', 'ne[G3, G4]', 'ne[G3, A3]', 'ne[G3, I2]', 'ne[G4, H4]', 'ne[G4, G6]', 'ne[G4, E4]', 'ne[G4, G1]', 'ne[G4, G3]', 'ne[G4, B4]', 'ne[G4, I4]', 'ne[G4, I5]', 'ne[G4, H6]', 'ne[G4, G5]', 'ne[G4, C4]', 'ne[G4, F4]', 'ne[G4, G2]', 'ne[G4, G7]', 'ne[G4, G8]', 'ne[G4, D4]', 'ne[G4, I6]', 'ne[G4, A4]', 'ne[G4, G9]', 'ne[G4, H5]', 'ne[G5, H4]', 'ne[G5, G6]', 'ne[G5, F5]', 'ne[G5, G1]', 'ne[G5, G3]', 'ne[G5, D5]', 'ne[G5, I5]', 'ne[G5, B5]', 'ne[G5, I4]', 'ne[G5, H6]', 'ne[G5, G2]', 'ne[G5, G7]', 'ne[G5, G8]', 'ne[G5, E5]', 'ne[G5, I6]', 'ne[G5, C5]', 'ne[G5, A5]', 'ne[G5, G9]', 'ne[G5, H5]', 'ne[G5, G4]', 'ne[G6, H4]', 'ne[G6, C6]', 'ne[G6, A6]', 'ne[G6, G1]', 'ne[G6, G3]', 'ne[G6, I4]', 'ne[G6, I5]', 'ne[G6, H6]', 'ne[G6, G5]', 'ne[G6, D6]', 'ne[G6, G2]', 'ne[G6, G7]', 'ne[G6, G8]', 'ne[G6, F6]', 'ne[G6, I6]', 'ne[G6, G9]', 'ne[G6, E6]', 'ne[G6, H5]', 'ne[G6, B6]', 'ne[G6, G4]', 'ne[G7, G6]', 'ne[G7, I7]', 'ne[G7, G1]', 'ne[G7, G3]', 'ne[G7, H9]', 'ne[G7, C7]', 'ne[G7, G5]', 'ne[G7, E7]', 'ne[G7, A7]', 'ne[G7, G2]', 'ne[G7, G8]', 'ne[G7, B7]', 'ne[G7, H8]', 'ne[G7, H7]', 'ne[G7, I9]', 'ne[G7, G9]', 'ne[G7, F7]', 'ne[G7, I8]', 'ne[G7, G4]', 'ne[G7, D7]', 'ne[G8, F8]', 'ne[G8, G6]', 'ne[G8, I7]', 'ne[G8, D8]', 'ne[G8, G1]', 'ne[G8, G3]', 'ne[G8, C8]', 'ne[G8, H9]', 'ne[G8, G5]', 'ne[G8, G2]', 'ne[G8, G7]', 'ne[G8, A8]', 'ne[G8, H8]', 'ne[G8, B8]', 'ne[G8, H7]', 'ne[G8, I9]', 'ne[G8, G9]', 'ne[G8, I8]', 'ne[G8, G4]', 'ne[G8, E8]', 'ne[G9, G6]', 'ne[G9, C9]', 'ne[G9, I7]', 'ne[G9, G1]', 'ne[G9, G3]', 'ne[G9, H9]', 'ne[G9, G5]', 'ne[G9, D9]', 'ne[G9, G2]', 'ne[G9, G7]', 'ne[G9, B9]', 'ne[G9, G8]', 'ne[G9, H8]', 'ne[G9, E9]', 'ne[G9, H7]', 'ne[G9, I9]', 'ne[G9, F9]', 'ne[G9, A9]', 'ne[G9, I8]', 'ne[G9, G4]', 'ne[H1, H4]', 'ne[H1, F1]', 'ne[H1, G1]', 'ne[H1, G3]', 'ne[H1, H9]', 'ne[H1, H6]', 'ne[H1, H2]', 'ne[H1, H3]', 'ne[H1, E1]', 'ne[H1, C1]', 'ne[H1, G2]', 'ne[H1, D1]', 'ne[H1, H8]', 'ne[H1, H7]', 'ne[H1, A1]', 'ne[H1, I1]', 'ne[H1, H5]', 'ne[H1, B1]', 'ne[H1, I3]', 'ne[H1, I2]', 'ne[H2, H4]', 'ne[H2, A2]', 'ne[H2, G1]', 'ne[H2, G3]', 'ne[H2, I2]', 'ne[H2, H1]', 'ne[H2, H9]', 'ne[H2, H6]', 'ne[H2, H3]', 'ne[H2, F2]', 'ne[H2, D2]', 'ne[H2, G2]', 'ne[H2, B2]', 'ne[H2, H8]', 'ne[H2, H7]', 'ne[H2, I1]', 'ne[H2, E2]', 'ne[H2, H5]', 'ne[H2, I3]', 'ne[H2, C2]', 'ne[H3, H4]', 'ne[H3, G1]', 'ne[H3, G3]', 'ne[H3, H1]', 'ne[H3, H9]', 'ne[H3, H6]', 'ne[H3, H2]', 'ne[H3, F3]', 'ne[H3, B3]', 'ne[H3, G2]', 'ne[H3, H8]', 'ne[H3, C3]', 'ne[H3, H7]', 'ne[H3, D3]', 'ne[H3, I1]', 'ne[H3, E3]', 'ne[H3, H5]', 'ne[H3, I3]', 'ne[H3, A3]', 'ne[H3, I2]', 'ne[H4, G6]', 'ne[H4, E4]', 'ne[H4, B4]', 'ne[H4, I4]', 'ne[H4, H1]', 'ne[H4, I5]', 'ne[H4, H9]', 'ne[H4, H6]', 'ne[H4, G5]', 'ne[H4, H2]', 'ne[H4, H3]', 'ne[H4, C4]', 'ne[H4, F4]', 'ne[H4, D4]', 'ne[H4, I6]', 'ne[H4, A4]', 'ne[H4, H8]', 'ne[H4, H7]', 'ne[H4, H5]', 'ne[H4, G4]', 'ne[H5, H4]', 'ne[H5, G6]', 'ne[H5, F5]', 'ne[H5, D5]', 'ne[H5, I5]', 'ne[H5, B5]', 'ne[H5, H1]', 'ne[H5, I4]', 'ne[H5, H9]', 'ne[H5, H6]', 'ne[H5, G5]', 'ne[H5, H2]', 'ne[H5, H3]', 'ne[H5, E5]', 'ne[H5, I6]', 'ne[H5, H8]', 'ne[H5, C5]', 'ne[H5, H7]', 'ne[H5, A5]', 'ne[H5, G4]', 'ne[H6, H4]', 'ne[H6, G6]', 'ne[H6, C6]', 'ne[H6, A6]', 'ne[H6, I4]', 'ne[H6, H1]', 'ne[H6, I5]', 'ne[H6, H9]', 'ne[H6, G5]', 'ne[H6, H2]', 'ne[H6, H3]', 'ne[H6, D6]', 'ne[H6, F6]', 'ne[H6, I6]', 'ne[H6, H8]', 'ne[H6, H7]', 'ne[H6, E6]', 'ne[H6, H5]', 'ne[H6, B6]', 'ne[H6, G4]', 'ne[H7, H4]', 'ne[H7, I7]', 'ne[H7, H1]', 'ne[H7, H9]', 'ne[H7, C7]', 'ne[H7, H6]', 'ne[H7, E7]', 'ne[H7, H2]', 'ne[H7, A7]', 'ne[H7, H3]', 'ne[H7, G7]', 'ne[H7, G8]', 'ne[H7, B7]', 'ne[H7, H8]', 'ne[H7, I9]', 'ne[H7, G9]', 'ne[H7, F7]', 'ne[H7, H5]', 'ne[H7, I8]', 'ne[H7, D7]', 'ne[H8, F8]', 'ne[H8, H4]', 'ne[H8, I7]', 'ne[H8, D8]', 'ne[H8, C8]', 'ne[H8, H1]', 'ne[H8, H9]', 'ne[H8, H6]', 'ne[H8, H2]', 'ne[H8, H3]', 'ne[H8, G7]', 'ne[H8, G8]', 'ne[H8, A8]', 'ne[H8, B8]', 'ne[H8, H7]', 'ne[H8, I9]', 'ne[H8, G9]', 'ne[H8, I8]', 'ne[H8, H5]', 'ne[H8, E8]', 'ne[H9, H4]', 'ne[H9, C9]', 'ne[H9, I7]', 'ne[H9, H1]', 'ne[H9, H6]', 'ne[H9, H2]', 'ne[H9, D9]', 'ne[H9, H3]', 'ne[H9, G7]', 'ne[H9, B9]', 'ne[H9, G8]', 'ne[H9, H8]', 'ne[H9, E9]', 'ne[H9, H7]', 'ne[H9, I9]', 'ne[H9, F9]', 'ne[H9, A9]', 'ne[H9, G9]', 'ne[H9, H5]', 'ne[H9, I8]', 'ne[I1, I7]', 'ne[I1, F1]', 'ne[I1, G1]', 'ne[I1, G3]', 'ne[I1, I4]', 'ne[I1, H1]', 'ne[I1, I5]', 'ne[I1, H2]', 'ne[I1, H3]', 'ne[I1, E1]', 'ne[I1, C1]', 'ne[I1, G2]', 'ne[I1, D1]', 'ne[I1, I6]', 'ne[I1, A1]', 'ne[I1, I9]', 'ne[I1, I8]', 'ne[I1, B1]', 'ne[I1, I3]', 'ne[I1, I2]', 'ne[I2, I7]', 'ne[I2, A2]', 'ne[I2, G1]', 'ne[I2, G3]', 'ne[I2, I4]', 'ne[I2, I5]', 'ne[I2, H1]', 'ne[I2, H2]', 'ne[I2, H3]', 'ne[I2, F2]', 'ne[I2, D2]', 'ne[I2, G2]', 'ne[I2, B2]', 'ne[I2, I6]', 'ne[I2, I9]', 'ne[I2, I1]', 'ne[I2, E2]', 'ne[I2, I8]', 'ne[I2, I3]', 'ne[I2, C2]', 'ne[I3, I7]', 'ne[I3, G1]', 'ne[I3, G3]', 'ne[I3, I4]', 'ne[I3, I5]', 'ne[I3, H1]', 'ne[I3, H2]', 'ne[I3, H3]', 'ne[I3, F3]', 'ne[I3, B3]', 'ne[I3, G2]', 'ne[I3, I6]', 'ne[I3, C3]', 'ne[I3, D3]', 'ne[I3, I9]', 'ne[I3, I1]', 'ne[I3, E3]', 'ne[I3, I8]', 'ne[I3, A3]', 'ne[I3, I2]', 'ne[I4, H4]', 'ne[I4, G6]', 'ne[I4, I7]', 'ne[I4, E4]', 'ne[I4, B4]', 'ne[I4, I5]', 'ne[I4, H6]', 'ne[I4, G5]', 'ne[I4, C4]', 'ne[I4, F4]', 'ne[I4, D4]', 'ne[I4, I6]', 'ne[I4, A4]', 'ne[I4, I9]', 'ne[I4, I1]', 'ne[I4, I8]', 'ne[I4, H5]', 'ne[I4, I3]', 'ne[I4, G4]', 'ne[I4, I2]', 'ne[I5, H4]', 'ne[I5, G6]', 'ne[I5, I7]', 'ne[I5, F5]', 'ne[I5, D5]', 'ne[I5, B5]', 'ne[I5, I4]', 'ne[I5, H6]', 'ne[I5, G5]', 'ne[I5, E5]', 'ne[I5, I6]', 'ne[I5, C5]', 'ne[I5, A5]', 'ne[I5, I9]', 'ne[I5, I1]', 'ne[I5, H5]', 'ne[I5, I8]', 'ne[I5, I3]', 'ne[I5, G4]', 'ne[I5, I2]', 'ne[I6, H4]', 'ne[I6, G6]', 'ne[I6, I7]', 'ne[I6, C6]', 'ne[I6, A6]', 'ne[I6, I4]', 'ne[I6, I5]', 'ne[I6, H6]', 'ne[I6, G5]', 'ne[I6, D6]', 'ne[I6, F6]', 'ne[I6, I9]', 'ne[I6, I1]', 'ne[I6, E6]', 'ne[I6, I8]', 'ne[I6, H5]', 'ne[I6, B6]', 'ne[I6, I3]', 'ne[I6, G4]', 'ne[I6, I2]', 'ne[I7, I4]', 'ne[I7, I5]', 'ne[I7, H9]', 'ne[I7, C7]', 'ne[I7, E7]', 'ne[I7, A7]', 'ne[I7, G7]', 'ne[I7, G8]', 'ne[I7, B7]', 'ne[I7, I6]', 'ne[I7, H8]', 'ne[I7, H7]', 'ne[I7, I9]', 'ne[I7, I1]', 'ne[I7, G9]', 'ne[I7, F7]', 'ne[I7, I8]', 'ne[I7, I3]', 'ne[I7, D7]', 'ne[I7, I2]', 'ne[I8, F8]', 'ne[I8, I7]', 'ne[I8, D8]', 'ne[I8, C8]', 'ne[I8, I4]', 'ne[I8, I5]', 'ne[I8, H9]', 'ne[I8, G7]', 'ne[I8, G8]', 'ne[I8, A8]', 'ne[I8, H8]', 'ne[I8, I6]', 'ne[I8, B8]', 'ne[I8, H7]', 'ne[I8, I9]', 'ne[I8, I1]', 'ne[I8, G9]', 'ne[I8, I3]', 'ne[I8, E8]', 'ne[I8, I2]', 'ne[I9, C9]', 'ne[I9, I7]', 'ne[I9, I4]', 'ne[I9, I5]', 'ne[I9, H9]', 'ne[I9, D9]', 'ne[I9, G7]', 'ne[I9, B9]', 'ne[I9, G8]', 'ne[I9, I6]', 'ne[I9, H8]', 'ne[I9, E9]', 'ne[I9, H7]', 'ne[I9, F9]', 'ne[I9, A9]', 'ne[I9, G9]', 'ne[I9, I1]', 'ne[I9, I8]', 'ne[I9, I3]', 'ne[I9, I2]'])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code\n",
    "grid_to_csp(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4.3\n",
    "\n",
    "Descibe what do nodes represent in the search tree. Explain your choice of the search algorithm and compare it with any other search algorithm implemented in this assignment. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
